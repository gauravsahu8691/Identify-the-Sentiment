{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model is overfitting since it is giving us 100 f1_score but since it also gives good test prediction so we are kepping it for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, \\\n",
    "                            confusion_matrix, plot_confusion_matrix, precision_recall_curve, plot_roc_curve, \\\n",
    "                            roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "random_forest = RandomForestClassifier(oob_score=True, n_estimators=100, class_weight=\"balanced\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_report(y_true, y_pred):\n",
    "    \n",
    "    print(\"Precision :  \", precision_score(y_true, y_pred))\n",
    "    print(\"Recall    :  \", recall_score(y_true, y_pred))\n",
    "    print(\"F1-score  :  \", f1_score(y_true, y_pred))\n",
    "    print(\"Accuracy  :  \", accuracy_score(y_true, y_pred))\n",
    "    print(\"ROC AUC   :  \", roc_auc_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../preprocessed_data.csv\")\n",
    "test_data = pd.read_csv(\"../preprocessed_test_data.csv\").drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['tweet', 'label', 'word_count', 'charcter_count', 'hashtag_count',\n",
       "       'vulgar_word_count', 'symbol_count', 'stop_word_count',\n",
       "       'sentiment_score', 'topic_1', 'topic_2', 'topic_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns=[\"topic_4\", \"topic_5\"], inplace=True)\n",
    "test_data.drop(columns=[\"topic_4\", \"topic_5\"], inplace=True)\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(tweet):\n",
    "    \n",
    "#     new_tweet = \"\"\n",
    "#     for word in tweet.split():\n",
    "#         if word not in most_common:\n",
    "#             new_tweet += word\n",
    "#             new_tweet += \" \"\n",
    "        \n",
    "#     return new_tweet\n",
    "\n",
    "# most_common = []\n",
    "# for word in Counter(\"\".join(data[\"tweet\"]).split()).most_common()[:100]:\n",
    "#     score = sid.polarity_scores(word[0])[\"compound\"]\n",
    "#     if (score > -0.2 and score < 0.2) :\n",
    "#         most_common.append(word[0])\n",
    "\n",
    "# data[\"tweet\"] = data[\"tweet\"].apply(clean)\n",
    "# test_data[\"tweet\"] = test_data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for word in Counter(\"\".join(data[\"tweet\"]).split()).most_common()[:100]:\n",
    "#         score = sid.polarity_scores(word[0])[\"compound\"]\n",
    "#         if (score > -0.2 and score < 0.2) :\n",
    "#             print(word[0], \" : \", score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tfidf_vector = tfidf_vectorizer.fit_transform(data[\"tweet\"])\n",
    "# test_tfidf_vector = tfidf_vectorizer.transform(test_data[\"tweet\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# pca = PCA(n_components=1)\n",
    "# columns = []\n",
    "# for i in range(pca.n_components):\n",
    "#     columns.append(\"feature \" + str(i))\n",
    "    \n",
    "# pca_transformed = pd.DataFrame(pca.fit_transform(tfidf_vector.todense()), columns=columns)\n",
    "# test_pca_transformed = pd.DataFrame(pca.transform(test_tfidf_vector.todense()), columns=columns)\n",
    "\n",
    "# for feature in columns:\n",
    "#     data[feature] = pca_transformed[feature]\n",
    "#     test_data[feature] = test_pca_transformed[feature]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8878787878787879"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest = RandomForestClassifier(n_estimators=50, max_depth=6)\n",
    "np.array(cross_val_score(random_forest, data.drop(columns=[\"tweet\", \"label\"]), data[\"label\"], cv=10)).mean()\n",
    "# 0.891919191919192"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(max_depth=6, n_estimators=50)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_forest.fit(data.drop(columns=[\"tweet\", \"label\"]), data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({\"label\": random_forest.predict(test_data.drop(columns=[\"tweet\"]))})\n",
    "prediction.to_csv(\"random_forest_prediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(random_forest, open(\"random_forest.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.72043\n",
       "1    0.27957\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0    0.716846\n",
    "# 1    0.283154"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}

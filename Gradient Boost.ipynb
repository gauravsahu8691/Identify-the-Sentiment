{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from collections import Counter\n",
    "from sklearn.metrics import classification_report, precision_score, recall_score, f1_score, accuracy_score, \\\n",
    "                            confusion_matrix, plot_confusion_matrix, precision_recall_curve, plot_roc_curve, \\\n",
    "                            roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from keras.optimizers import RMSprop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "tfidf_vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classifier_report(y_true, y_pred):\n",
    "    \n",
    "    print(\"Precision :  \", precision_score(y_true, y_pred))\n",
    "    print(\"Recall    :  \", recall_score(y_true, y_pred))\n",
    "    print(\"F1-score  :  \", f1_score(y_true, y_pred))\n",
    "    print(\"Accuracy  :  \", accuracy_score(y_true, y_pred))\n",
    "    print(\"ROC AUC   :  \", roc_auc_score(y_true, y_pred))\n",
    "    print(\"Confusion Matrix : \")\n",
    "    print(confusion_matrix(y_true, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "gradient_boost = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../preprocessed_data.csv\")\n",
    "test_data = pd.read_csv(\"../preprocessed_test_data.csv\").drop(columns=[\"id\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def clean(tweet):\n",
    "    \n",
    "#     new_tweet = \"\"\n",
    "#     for word in tweet.split():\n",
    "#         if word not in most_common:\n",
    "#             new_tweet += word\n",
    "#             new_tweet += \" \"\n",
    "        \n",
    "#     return new_tweet\n",
    "\n",
    "# most_common = []\n",
    "# for word in Counter(\"\".join(data[\"tweet\"]).split()).most_common()[:20]:\n",
    "#     most_common.append(word[0])\n",
    "\n",
    "# data[\"tweet\"] = data[\"tweet\"].apply(clean)\n",
    "# test_data[\"tweet\"] = test_data[\"tweet\"].apply(clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.897348484848485"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(cross_val_score(gradient_boost, data.drop(columns=[\"tweet\", \"label\"]), data[\"label\"], cv=10)).mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingClassifier()"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gradient_boost.fit(data.drop(columns=[\"tweet\", \"label\"]), data[\"label\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction = pd.DataFrame({\"label\": gradient_boost.predict(test_data.drop(columns=[\"tweet\"]))})\n",
    "prediction.to_csv(\"gradient_boost.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "pickle.dump(gradient_boost, open(\"gradient_boost.sav\", \"wb\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.698925\n",
       "1    0.301075\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction[\"label\"].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
